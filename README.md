## ğŸ‘‹ Welcome to SKD's Github 
- **ML Research Engineer** at [PYLER](https://pyler.tech/), focused on multimodal deep learning, computer vision, and video understanding.
- Received a Bachelor's degree in Computer Science from [The Catholic Univerity of Korea](https://www.catholic.ac.kr/ko/index.do), with Magna Cum Laude.
- Received a Master's degree in Computer Science from [Yonsei University](https://www.yonsei.ac.kr), advised by Prof. Sanghyun Park.

[![GitHub stats](https://github-readme-stats.vercel.app/api?username=skiddieahn&count_private=true&show_icons=true&theme=vue&hide_border=true&rank_icon=github)](https://github.com/SkiddieAhn)

## ğŸ™ Experience
### PYLER
> **ML Research Enginner** (2025.07 ~ present)  
> **Technical Research Personnel**
- Multimodal Deep Learning
- Video Understanding
  
### Data Engineering Lab
> **AI Researcher** (2022.03 ~ 2025.05)  
> **Yonsei Univ. Dept of Computer Science**
- Video Anomaly Detection
- Medical Image Segmentation
  
## ğŸ“œ Publications
<details>
<summary><b>International Papers</b></summary>

1. Sunghyun Ahn*, Youngwan Jo*, Kijung Lee, Sein Kwon, Inpyo Hong, and Sanghyun Park. (*equally contributed) <b>"AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM"</b> arXiv, Preprint [[View](https://arxiv.org/abs/2503.04504)][[Code](https://github.com/SkiddieAhn/Paper-AnyAnomaly)]
2. Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, and Sanghyun Park. <b>"GranQ: Granular Zero-Shot Quantization with Channel-Wise Activation Scaling in QAT"</b> arXiv, Preprint [[View](https://arxiv.org/abs/2503.18339)]
3. Kijung Lee, Youngwan Jo, Sunghyun Ahn, and Sanghyun Park. <b>"MDVAD: Multimodal Diffusion for Video Anomaly Detection"</b> Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), regular paper, June 2025. (BK, IF=1) [[View](https://link.springer.com/chapter/10.1007/978-981-96-8170-9_10)]
4. Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, and Sanghyun Park. <b>"Advanced Knowledge Transfer: Refined Feature Distillation for Zero-Shot Quantization in Edge Computing"</b> ACM/SIGAPP Symposium On Applied Computing (SAC), regular paper, Mar 2025. (BK, IF=1) [[View](https://arxiv.org/abs/2412.19125)]
5. Sunghyun Ahn, Youngwan Jo, Kijung Lee, and Sanghyun Park. <b>"VideoPatchCore: An Effective Method to Memorize Normality for Video Anomaly Detection"</b> Asian Conference on Computer Vision (ACCV), regular paper, Sep 2024. (BK, IF=1) [[View](https://arxiv.org/abs/2409.16225)][[Code](https://github.com/SkiddieAhn/Paper-VideoPatchCore)] 
6. **[SCIE]** Seungkyun Hong*, Sunghyun Ahn*, Youngwan Jo, and Sanghyun Park. (*equally contributed) <b>"Making Anomalies More Anomalous: Video Anomaly Detection Using a Novel Generator and Destroyer"</b> IEEE Access (2024): 36712-36726. (IF: 3.9, JCR: Q2) [[View](https://ieeexplore.ieee.org/document/10462109/)][[Code](https://github.com/SkiddieAhn/Paper-Making-Anomalies-More-Anomalous)] 
7. Seungkyun Hong*, Sunghyun Ahn*, Youngwan Jo, and Sanghyun Park. (*equally contributed) <b>"Dual Stream Fusion U-Net Transformers for
3D Medical Image Segmentation"</b> IEEE International Conference on Big Data and Smart Computing (BigComp), regular paper, Feb 2024. [[View](https://ieeexplore.ieee.org/abstract/document/10488278)][[Code](https://github.com/SkiddieAhn/Paper-DS-UNETR)] 

  
</details>

<details>
<summary><b>Domestic Papers</b></summary>

1. ì•ˆì„±í˜„, ì¡°ì˜ì™„, ì´ê¸°ì •, ê¶Œì„¸ì¸ and ë°•ìƒí˜„. <b>"Anomaly LVLM: LVLMì„ í™œìš©í•œ ì‚¬ìš©ì ë§ì¶¤í˜• ë¹„ë””ì˜¤ ì´ìƒ íƒì§€ ì—°êµ¬"</b> í•œêµ­ì •ë³´ê³¼í•™íšŒ í•™ìˆ ë°œí‘œë…¼ë¬¸ì§‘ (2024): 120-122. [[View](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE12041808)] ğŸ†
2. ê¹€ì€ì§€, ì•ˆì„±í˜„, ì´íš¨ì • and ë°•ìƒí˜„. <b>"MSPD: ìê¸° ì§€ë„ í•™ìŠµ ê¸°ë°˜ ì €ì„ ëŸ‰ CT ë””ë…¸ì´ì§•ì„ ìœ„í•œ ë‹¤í•´ìƒë„ í”½ì…€ ë¬´ì‘ìœ„ ë°°ì—´ ë‹¤ìš´ìƒ˜í”Œë§ ë„¤íŠ¸ì›Œí¬"</b> í•œêµ­ì •ë³´ê³¼í•™íšŒ í•™ìˆ ë°œí‘œë…¼ë¬¸ì§‘ (2024): 123-125. [[View](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE12041810)]
3. í™ì¸í‘œ, ì¡°ì˜ì™„, ì•ˆì„±í˜„, ê¹€ì€ì§€, ê¶Œì„¸ì¸ and ë°•ìƒí˜„. <b>"DQ-ResUNet: ì˜ë£Œ ì˜ìƒ ë¶„í• ì˜ íš¨ìœ¨ì„± ê°œì„ ì„ ìœ„í•œ ë™ì  ì–‘ìí™” ê¸°ë°˜ ìµœì í™”"</b> í•œêµ­ì •ë³´ê³¼í•™íšŒ í•™ìˆ ë°œí‘œë…¼ë¬¸ì§‘ (2024): 708-710. [[View](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11861961)]
4. ì´ê¸°ì •, ì•ˆì„±í˜„, ê¹€í˜„ì§„ and ë°•ìƒí˜„. <b>"FFAE: ë¹„ë””ì˜¤ ì´ìƒ íƒì§€ë¥¼ ìœ„í•œ ë¹„ë””ì˜¤ í”„ë ˆì„ ì „ì²˜ë¦¬ ë° íŠ¹ì§• ìœµí•© ë°©ë²•"</b> í•œêµ­ì •ë³´ê³¼í•™íšŒ í•™ìˆ ë°œí‘œë…¼ë¬¸ì§‘ (2023): 526-528. [[View](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11705154)]
5. ì•ˆì„±í˜„, ê¹€í™˜í¬, ê¶Œì„¸ì¸ and ë°•ìƒí˜„. <b>"C-Swin UNETR: 3D ì˜ë£Œ ì˜ìƒ ë¶„í• ì„ ìœ„í•œ ì±„ë„ ì–´í…ì…˜ì´ ì ìš©ëœ Swin Transformer"</b> í•œêµ­ì •ë³´ê³¼í•™íšŒ í•™ìˆ ë°œí‘œë…¼ë¬¸ì§‘ (2023): 787-789. [[View](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11488179)]
6. ì•ˆì„±í˜„, ì¡°ì˜ì™„, and ë°•ìƒí˜„. <b>"ë‹¤ì¤‘ ê°ì²´ ë¹„ë””ì˜¤ì—ì„œì˜ ì–´í…ì…˜ ê¸°ë°˜ ë‹¨ì¼ ê°ì²´ ì¶”ì  ëª¨ë¸ ì—°êµ¬"</b> í•œêµ­ì •ë³´ê³¼í•™íšŒ í•™ìˆ ë°œí‘œë…¼ë¬¸ì§‘ (2022): 628-630. [[View](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11224192)]
   
</details>

<details>
<summary><b>International Patents</b></summary>

1. Kijung Lee, Youngwan Jo, Sunghyun Ahn, and Sanghyun Park. <b>"Method of Detecting Video Anomaly on the Basis of Multimodal Diffusion and Device Therefor"</b> ID: 19/078,589 (2025). [[View](http://delab.yonsei.ac.kr/publications/international/patent/2025-03-14-METHOD%20OF%20DETECTING%20VIDEO%20ANOMALY%20ON%20BASIS%20OF%20MULTIMODAL%20DIFFUSION%20AND%20DEVICE%20THEREFOR/)]
2. Seungkyun Hong, Sunghyun Ahn, Youngwan Jo, and Sanghyun Park. <b>"Image segmentation method using dual attention and the device utilizing it"</b> ID: PCT/KR2023/020370 (2023). [[View](http://delab.yonsei.ac.kr/publications/international/patent/2023-12-12-Image%20segmentation%20method%20using%20dual%20attention%20and%20the%20device%20utilizing%20it/)]
   
</details>

<details>
<summary><b>Domestic Patents</b></summary>

1. ì´ê¸°ì •, ì¡°ì˜ì™„, ì•ˆì„±í˜„, and ë°•ìƒí˜„. <b>"ë‹¤ì¤‘ëª¨ë‹¬ í™•ì‚° ê¸°ë°˜ì˜ ë¹„ë””ì˜¤ ì´ìƒ íƒì§€ ë°©ë²• ë° ì¥ì¹˜"</b> ID: 10-2024-0055081 (2024). [[View](http://delab.yonsei.ac.kr/publications/domestic/patent/2024-04-25-%EB%8D%94%EC%A4%91%EB%AA%A8%EB%8B%AC-%ED%99%95%EC%82%B0-%EA%B8%B0%EB%B0%98%EC%9D%98-%EB%B9%84%EB%94%94%EC%98%A4-%EC%9D%B4%EC%83%81-%ED%83%90%EC%A7%80-%EB%B0%A9%EB%B2%95-%EB%B0%8F-%EC%9E%A5%EC%B9%98/)]
2. í™ìŠ¹ê· , ì•ˆì„±í˜„, ì¡°ì˜ì™„, and ë°•ìƒí˜„. <b>"F2LM ê¸°ë°˜ì˜ ë¹„ë””ì˜¤ ì´ìƒ íƒì§€ ë°©ë²• ë° ì¥ì¹˜"</b> ID: 10-2024-0055080 (2024). [[View](http://delab.yonsei.ac.kr/publications/domestic/patent/2024-04-25-F2LM-%EA%B8%B0%EB%B0%98%EC%9D%98-%EB%B9%84%EB%94%94%EC%98%A4-%EC%9D%B4%EC%83%81-%ED%83%90%EC%A7%80-%EB%B0%A9%EB%B2%95-%EB%B0%8F-%EC%9E%A5%EC%B9%98/)]
3. í™ìŠ¹ê· , ì•ˆì„±í˜„, ì¡°ì˜ì™„, and ë°•ìƒí˜„. <b>"ì´ì¤‘ ì–´í…ì…˜ì„ ì´ìš©í•œ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ë° ì´ë¥¼ í™œìš©í•œ ì¥ì¹˜"</b> ID: 10-2023-0124697 (2023). [[View](http://delab.yonsei.ac.kr/publications/domestic/patent/2023-09-19-%EC%9D%B4%EC%A4%91%20%EC%96%B4%ED%85%90%EC%85%98%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9D%B4%EB%AF%B8%EC%A7%80%20%EC%84%B8%EA%B7%B8%EB%A9%98%ED%85%8C%EC%9D%B4%EC%85%98%20%EB%B0%A9%EB%B2%95%20%EB%B0%8F%20%EC%9D%B4%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%EC%9E%A5%EC%B9%98/)]
   
</details>


## ğŸ¤™ Contact
**E-mail:** skd@yonsei.ac.kr, sunghyun.ahn@pyler.tech **CV:** [view](https://shacoding.com/wp-content/uploads/2019/07/SHA_CV_0705.pdf), [slide](https://shacoding.com/wp-content/uploads/2019/07/SHA_PF_0626.pdf)
</p>
<p>
<a href="https://scholar.google.com/citations?user=mKchEwoAAAAJ&hl=ko" target="_blank">
<img src="https://img.shields.io/badge/Google%20Scholar-4285F4?style=flat&logo=Google%20Scholar&logoColor=white" /></a>
<a href="https://www.linkedin.com/in/sunghyunahn-ai" target="_blank">
<img src="https://img.shields.io/badge/-LinkedIn-blue?style=flat&logo=Linkedin&logoColor=white" /></a>
<a href="https://shacoding.com/" target="_blank">
<img src="https://img.shields.io/badge/Tech Blog-21759B?style=flat&logo=wordpress&logoColor=white" /></a>
</p>
